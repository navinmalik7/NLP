{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['amazing' 'enjoy' 'is' 'learning' 'love' 'nlp']\n",
      "BoW Matrix:\n",
      " [[0 0 0 0 1 1]\n",
      " [1 0 1 0 0 1]\n",
      " [0 1 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love NLP.\",\n",
    "    \"NLP is amazing.\",\n",
    "    \"I enjoy learning NLP.\"\n",
    "]\n",
    "\n",
    "# Create BoW model\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array and display\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "print(\"BoW Matrix:\\n\", bow_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['amazing' 'enjoy' 'is' 'learning' 'love' 'nlp']\n",
      "TF-IDF Matrix:\n",
      " [[0.         0.         0.         0.         0.861037   0.50854232]\n",
      " [0.65249088 0.         0.65249088 0.         0.         0.38537163]\n",
      " [0.         0.65249088 0.         0.65249088 0.         0.38537163]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love NLP.\",\n",
    "    \"NLP is amazing.\",\n",
    "    \"I enjoy learning NLP.\"\n",
    "]\n",
    "\n",
    "# Create TF-IDF model\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array and display\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'NLP': [-0.00536227  0.00236431  0.0510335   0.09009273 -0.0930295  -0.07116809\n",
      "  0.06458873  0.08972988 -0.05015428 -0.03763372]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample sentences\n",
    "sentences = [\n",
    "    [\"I\", \"love\", \"NLP\"],\n",
    "    [\"NLP\", \"is\", \"amazing\"],\n",
    "    [\"I\", \"enjoy\", \"learning\", \"NLP\"]\n",
    "]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=10, window=2, min_count=1, sg=1)  # sg=1 for Skip-Gram\n",
    "\n",
    "# Get vector for a word\n",
    "print(\"Vector for 'NLP':\", model.wv['NLP'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
