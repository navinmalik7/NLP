{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: The, POS: DET, Dependency: det\n",
      "Word: quick, POS: ADJ, Dependency: amod\n",
      "Word: brown, POS: ADJ, Dependency: amod\n",
      "Word: fox, POS: NOUN, Dependency: nsubj\n",
      "Word: jumps, POS: VERB, Dependency: ROOT\n",
      "Word: over, POS: ADP, Dependency: prep\n",
      "Word: the, POS: DET, Dependency: det\n",
      "Word: lazy, POS: ADJ, Dependency: amod\n",
      "Word: dog, POS: NOUN, Dependency: pobj\n",
      "Word: ., POS: PUNCT, Dependency: punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Parse sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Display parsed sentence\n",
    "for token in doc:\n",
    "    print(f\"Word: {token.text}, POS: {token.pos_}, Dependency: {token.dep_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b5092bd040a74500bf1b47a34e5bcc68-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">John</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">loves</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">playing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">football</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">park.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b5092bd040a74500bf1b47a34e5bcc68-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b5092bd040a74500bf1b47a34e5bcc68-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b5092bd040a74500bf1b47a34e5bcc68-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b5092bd040a74500bf1b47a34e5bcc68-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b5092bd040a74500bf1b47a34e5bcc68-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b5092bd040a74500bf1b47a34e5bcc68-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b5092bd040a74500bf1b47a34e5bcc68-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b5092bd040a74500bf1b47a34e5bcc68-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b5092bd040a74500bf1b47a34e5bcc68-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b5092bd040a74500bf1b47a34e5bcc68-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-b5092bd040a74500bf1b47a34e5bcc68-0-5\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1100.0,2.0 1100.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-b5092bd040a74500bf1b47a34e5bcc68-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,179.0 L1108.0,167.0 1092.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"John loves playing football in the park.\"\n",
    "\n",
    "# Parse sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Visualize dependency tree\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai', 'natural language']\n"
     ]
    }
   ],
   "source": [
    "import textblob\n",
    "\n",
    "# Sample text\n",
    "sentence = \"The intelligent AI system can process natural language efficiently.\"\n",
    "\n",
    "# Extract noun phrases\n",
    "blob = textblob.TextBlob(sentence)\n",
    "print(blob.noun_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'transformer' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Transformer-based English NLP model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp_trf \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_trf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Add coreference resolution to pipeline\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcoreferee\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    vocab (Vocab): A Vocab object. If True, a vocab is created.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable. Disabled\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m        pipes will be loaded but they won't be run unless you explicitly\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m        enable them by calling nlp.enable_pipe.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All other\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m        pipes will be disabled (but can be enabled later using nlp.enable_pipe).\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m    exclude (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to exclude. Excluded\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m        components won't be loaded.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    config (Dict[str, Any] / Config): Config overrides as nested dict or dict\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;124;03m        keyed by section values in dot notation.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_from_package\u001b[39m(\n\u001b[0;32m    453\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    459\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m SimpleFrozenDict(),\n\u001b[0;32m    460\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    461\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    name (str): The package name.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    vocab (Vocab / True): Optional vocab to pass in on initialization. If True,\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m \u001b[38;5;124;03m        a new Vocab object will be created.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable. Disabled\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m        pipes will be loaded but they won't be run unless you explicitly\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m        enable them by calling nlp.enable_pipe.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All other\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;124;03m        pipes will be disabled (and can be enabled using `nlp.enable_pipe`).\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03m    exclude (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to exclude. Excluded\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m        components won't be loaded.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    config (Dict[str, Any] / Config): Config overrides as nested dict or dict\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m        keyed by section values in dot notation.\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mload(vocab\u001b[38;5;241m=\u001b[39mvocab, disable\u001b[38;5;241m=\u001b[39mdisable, enable\u001b[38;5;241m=\u001b[39menable, exclude\u001b[38;5;241m=\u001b[39mexclude, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_from_path\u001b[39m(\n\u001b[0;32m    482\u001b[0m     model_path: Path,\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m SimpleFrozenDict(),\n\u001b[0;32m    490\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from a data directory path. Creates Language class with\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m    pipeline from config.cfg and then calls from_disk() with path.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[0;32m    494\u001b[0m \u001b[38;5;124;03m    model_path (Path): Model path.\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m    meta (Dict[str, Any]): Optional model meta.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m    vocab (Vocab / True): Optional vocab to pass in on initialization. If True,\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m        a new Vocab object will be created.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03m    disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable. Disabled\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m        pipes will be loaded but they won't be run unless you explicitly\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m        enable them by calling nlp.enable_pipe.\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;124;03m    enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All other\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m        pipes will be disabled (and can be enabled using `nlp.enable_pipe`).\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m    exclude (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to exclude. Excluded\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m        components won't be loaded.\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m    config (Dict[str, Any] / Config): Config overrides as nested dict or dict\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;124;03m        keyed by section values in dot notation.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mmodel_path))\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\en_core_web_trf\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_config\u001b[39m(\n\u001b[0;32m    671\u001b[0m     path: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m    672\u001b[0m     overrides: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m SimpleFrozenDict(),\n\u001b[0;32m    673\u001b[0m     interpolate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Config:\n\u001b[0;32m    675\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a config file. Takes care of path validation and section order.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \n\u001b[0;32m    677\u001b[0m \u001b[38;5;124;03m    path (Union[str, Path]): Path to the config file or \"-\" to read from stdin.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;124;03m    overrides: (Dict[str, Any]): Config overrides as nested dict or\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;124;03m        dict keyed by section values in dot notation.\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;124;03m    interpolate (bool): Whether to interpolate and resolve variables.\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;124;03m    RETURNS (Config): The loaded config.\u001b[39;00m\n\u001b[1;32m--> 682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    683\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m ensure_path(path)\n\u001b[0;32m    684\u001b[0m     config \u001b[38;5;241m=\u001b[39m Config(section_order\u001b[38;5;241m=\u001b[39mCONFIG_SECTION_ORDER)\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\util.py:539\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_from_config\u001b[39m(\n\u001b[0;32m    528\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config],\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m     validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    537\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an nlp object from a config. Expects the full config file including\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m \u001b[38;5;124;03m    a section \"nlp\" containing the settings for the nlp object.\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    meta (Dict[str, Any]): Optional model meta.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    vocab (Vocab / True): Optional vocab to pass in on initialization. If True,\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m        a new Vocab object will be created.\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable. Disabled\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        pipes will be loaded but they won't be run unless you explicitly\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m        enable them by calling nlp.enable_pipe.\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All other\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;124;03m        pipes will be disabled (and can be enabled using `nlp.enable_pipe`).\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m    exclude (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to exclude. Excluded\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m        components won't be loaded.\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;124;03m    auto_fill (bool): Whether to auto-fill config with missing defaults.\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m    validate (bool): Whether to show config validation errors.\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE985\u001b[38;5;241m.\u001b[39mformat(config\u001b[38;5;241m=\u001b[39mconfig))\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\util.py:587\u001b[0m, in \u001b[0;36mload_model_from_config\u001b[1;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sourced_components\u001b[39m(\n\u001b[0;32m    578\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config]\n\u001b[0;32m    579\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"RETURNS (List[str]): All sourced components in the original config,\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;124;03m    e.g. {\"source\": \"en_core_web_sm\"}. If the config contains a key\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03m    \"factory\", we assume it refers to a component factory.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    585\u001b[0m         name: cfg\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, cfg \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m--> 587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cfg \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cfg\n\u001b[0;32m    588\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\language.py:1864\u001b[0m, in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[0;32m   1859\u001b[0m     nlp\u001b[38;5;241m.\u001b[39madd_pipe(\n\u001b[0;32m   1860\u001b[0m         source_name, source\u001b[38;5;241m=\u001b[39msource_nlps[model], name\u001b[38;5;241m=\u001b[39mpipe_name\n\u001b[0;32m   1861\u001b[0m     )\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;66;03m# At this point after nlp.add_pipe, the listener map\u001b[39;00m\n\u001b[0;32m   1863\u001b[0m     \u001b[38;5;66;03m# corresponds to the new pipeline.\u001b[39;00m\n\u001b[1;32m-> 1864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m source_nlp_vectors_hashes:\n\u001b[0;32m   1865\u001b[0m     source_nlp_vectors_hashes[model] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhash\u001b[39m(\n\u001b[0;32m   1866\u001b[0m         source_nlps[model]\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mvectors\u001b[38;5;241m.\u001b[39mto_bytes(\n\u001b[0;32m   1867\u001b[0m             exclude\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1868\u001b[0m         )\n\u001b[0;32m   1869\u001b[0m     )\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sourced_vectors_hashes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mmeta:\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\language.py:821\u001b[0m, in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine where to insert a pipeline component based on the before/\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03mafter/first/last values.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03mRETURNS (int): The index of the new pipeline component.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    820\u001b[0m all_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m\"\u001b[39m: before, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter\u001b[39m\u001b[38;5;124m\"\u001b[39m: after, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m: first, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m: last}\n\u001b[1;32m--> 821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m [before, after, first, last]) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    823\u001b[0m         Errors\u001b[38;5;241m.\u001b[39mE006\u001b[38;5;241m.\u001b[39mformat(args\u001b[38;5;241m=\u001b[39mall_args, opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names)\n\u001b[0;32m    824\u001b[0m     )\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m [first, before, after]):\n",
      "File \u001b[1;32mc:\\Users\\navin\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\spacy\\language.py:690\u001b[0m, in \u001b[0;36mcreate_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    687\u001b[0m filled\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;66;03m# Merge the final filled config with the raw config (including non-\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# interpolated variables)\u001b[39;00m\n\u001b[1;32m--> 690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_config:\n\u001b[0;32m    691\u001b[0m     filled \u001b[38;5;241m=\u001b[39m filled\u001b[38;5;241m.\u001b[39mmerge(raw_config)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_configs[name] \u001b[38;5;241m=\u001b[39m filled\n",
      "\u001b[1;31mValueError\u001b[0m: [E002] Can't find factory for 'transformer' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "# Load Transformer-based English NLP model\n",
    "nlp_trf = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Add coreference resolution to pipeline\n",
    "import coreferee\n",
    "nlp_trf.add_pipe(\"coreferee\")\n",
    "\n",
    "# Sample text\n",
    "text = \"John saw a dog. He decided to adopt it.\"\n",
    "\n",
    "# Process text\n",
    "doc_trf = nlp_trf(text)\n",
    "\n",
    "# Get coreference-resolved text\n",
    "resolved_text = doc_trf._.coref_chains.resolve(doc_trf)\n",
    "print(resolved_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install neuralcoref\n",
    "\n",
    "import neuralcoref  \n",
    "\n",
    "# Add coreference resolution to spaCy  \n",
    "neuralcoref.add_to_pipe(nlp)  \n",
    "\n",
    "# Resolve coreferences  \n",
    "text = \"John loves his dog. He takes it to the park.\"  \n",
    "doc = nlp(text)  \n",
    "print(doc._.coref_resolved)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
